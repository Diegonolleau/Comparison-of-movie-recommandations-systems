{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96b7c9c",
   "metadata": {},
   "source": [
    "## SVD avec surprise : méthode de Simon Funk avec descente de gradient permettant de contourner la sparsité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236d0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "\n",
    "ratings = pd.read_csv(r\"C:\\Users\\nolle\\OneDrive\\Documents\\Université\\M2\\Mémoire\\Base de données traitées\\All.csv\")\n",
    "ratings = ratings[[\"userId\", \"title_clean_x\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce32728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir un Reader avec la plage des notes\n",
    "reader = Reader(rating_scale=(ratings.rating.min(), ratings.rating.max()))\n",
    "\n",
    "# Charger le dataset depuis le DataFrame\n",
    "data = Dataset.load_from_df(ratings[['userId', 'title_clean_x', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b9a64",
   "metadata": {},
   "source": [
    "##  I. Création de la fonction permettant d'obtenir les 10 recommandations les plus pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c53969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies_for_user(user_id, ratings_df, algo, n=10):\n",
    "    \"\"\"\n",
    "    Recommande les n meilleurs films non-vus par l'utilisateur à partir d'un modèle entraîné.\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): ID de l'utilisateur\n",
    "        ratings_df (pd.DataFrame): DataFrame contenant userId, title_clean_x, rating\n",
    "        algo (surprise.AlgoBase): Modèle entraîné (par ex. SVD)\n",
    "        n (int): Nombre de recommandations à retourner\n",
    "\n",
    "    Returns:\n",
    "        List of tuples: [(title, predicted_rating), ...]\n",
    "    \"\"\"\n",
    "    all_titles = ratings_df['title_clean_x'].unique()\n",
    "    seen_titles = ratings_df[ratings_df['userId'] == user_id]['title_clean_x'].unique()\n",
    "    unseen_titles = [title for title in all_titles if title not in seen_titles]\n",
    "\n",
    "    predictions = [algo.predict(user_id, title) for title in unseen_titles]\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    return [(pred.iid, round(pred.est, 2)) for pred in predictions[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "356d7d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pee-wee's Big Adventure (1985) — 4.54\n",
      "M (1931) — 4.53\n",
      "Double Indemnity (1944) — 4.49\n",
      "Who's Afraid of Virginia Woolf? (1966) — 4.46\n",
      "Modern Times (1936) — 4.45\n",
      "This Is Spinal Tap (1984) — 4.43\n",
      "Ran (1985) — 4.38\n",
      "Requiem for a Dream (2000) — 4.37\n",
      "Sanjuro (1962) — 4.33\n",
      "Roger & Me (1989) — 4.32\n"
     ]
    }
   ],
   "source": [
    "recommendations = recommend_movies_for_user(5, ratings, algo, n=10)\n",
    "for title, score in recommendations:\n",
    "    print(f\"{title} — {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197fb7c2",
   "metadata": {},
   "source": [
    "## II. Qualité des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b1c875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation réaliste par utilisateur:  33%|███▎      | 2000/6040 [45:32:01<91:58:42, 81.96s/it]      \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m trainset \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mbuild_full_trainset()\n\u001b[0;32m     38\u001b[0m algo \u001b[38;5;241m=\u001b[39m SVD()\n\u001b[1;32m---> 39\u001b[0m algo\u001b[38;5;241m.\u001b[39mfit(trainset)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Prédictions sur les 20 % cachés\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m user_test\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32mc:\\Users\\nolle\\anaconda3\\Lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:155\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.fit\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nolle\\anaconda3\\Lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:228\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nolle\\anaconda3\\Lib\\site-packages\\surprise\\trainset.py:194\u001b[0m, in \u001b[0;36mTrainset.all_ratings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u, u_ratings \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mur\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m u_ratings:\n\u001b[1;32m--> 194\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m u, i, r\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "true_ratings = []\n",
    "pred_ratings = []\n",
    "\n",
    "reader = Reader(rating_scale=(ratings['rating'].min(), ratings['rating'].max()))\n",
    "user_ids = ratings['userId'].unique()\n",
    "\n",
    "for user_id in tqdm(user_ids, desc=\"Validation réaliste par utilisateur\"):\n",
    "    # Toutes ses notes\n",
    "    user_data = ratings[ratings['userId'] == user_id]\n",
    "\n",
    "    # Skip s'il n'a pas assez de notes\n",
    "    if len(user_data) < 5:\n",
    "        continue\n",
    "\n",
    "    # Shuffle et split\n",
    "    user_data = user_data.sample(frac=1, random_state=42)\n",
    "    split_idx = int(0.8 * len(user_data))\n",
    "    user_train = user_data.iloc[:split_idx]\n",
    "    user_test = user_data.iloc[split_idx:]\n",
    "\n",
    "    # Données des autres utilisateurs\n",
    "    others_data = ratings[ratings['userId'] != user_id]\n",
    "\n",
    "    # Fusion pour entraînement : 80 % de l'utilisateur + tous les autres\n",
    "    train_df = pd.concat([user_train, others_data])\n",
    "\n",
    "    # Entraînement du modèle SVD collaboratif\n",
    "    data = Dataset.load_from_df(train_df[['userId', 'title_clean_x', 'rating']], reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo = SVD()\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    # Prédictions sur les 20 % cachés\n",
    "    for _, row in user_test.iterrows():\n",
    "        pred = algo.predict(uid=row['userId'], iid=row['title_clean_x']).est\n",
    "        true_ratings.append(row['rating'])\n",
    "        pred_ratings.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028eaccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interruption de la requête à 2000 utilisateurs testés sur 6040 car requête trop gourmande (46 heures pour 2000 utilisateurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff07c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8465\n",
      "MAE: 0.6641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "rmse = mean_squared_error(true_ratings, pred_ratings, squared=False)\n",
    "mae = mean_absolute_error(true_ratings, pred_ratings)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
